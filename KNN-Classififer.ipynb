{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b74811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "D:/Major Project/data_preprocessed_python/s01.dat\n",
      "D:/Major Project/data_preprocessed_python/s02.dat\n",
      "D:/Major Project/data_preprocessed_python/s03.dat\n",
      "D:/Major Project/data_preprocessed_python/s04.dat\n",
      "D:/Major Project/data_preprocessed_python/s05.dat\n",
      "D:/Major Project/data_preprocessed_python/s06.dat\n",
      "D:/Major Project/data_preprocessed_python/s07.dat\n",
      "D:/Major Project/data_preprocessed_python/s08.dat\n",
      "D:/Major Project/data_preprocessed_python/s09.dat\n",
      "D:/Major Project/data_preprocessed_python/s10.dat\n",
      "D:/Major Project/data_preprocessed_python/s11.dat\n",
      "D:/Major Project/data_preprocessed_python/s12.dat\n",
      "D:/Major Project/data_preprocessed_python/s13.dat\n",
      "D:/Major Project/data_preprocessed_python/s14.dat\n",
      "D:/Major Project/data_preprocessed_python/s15.dat\n",
      "D:/Major Project/data_preprocessed_python/s16.dat\n",
      "D:/Major Project/data_preprocessed_python/s17.dat\n",
      "D:/Major Project/data_preprocessed_python/s18.dat\n",
      "D:/Major Project/data_preprocessed_python/s19.dat\n",
      "D:/Major Project/data_preprocessed_python/s20.dat\n",
      "D:/Major Project/data_preprocessed_python/s21.dat\n",
      "D:/Major Project/data_preprocessed_python/s22.dat\n",
      "D:/Major Project/data_preprocessed_python/s23.dat\n",
      "D:/Major Project/data_preprocessed_python/s24.dat\n",
      "D:/Major Project/data_preprocessed_python/s25.dat\n",
      "D:/Major Project/data_preprocessed_python/s26.dat\n",
      "D:/Major Project/data_preprocessed_python/s27.dat\n",
      "D:/Major Project/data_preprocessed_python/s28.dat\n",
      "D:/Major Project/data_preprocessed_python/s29.dat\n",
      "D:/Major Project/data_preprocessed_python/s30.dat\n",
      "D:/Major Project/data_preprocessed_python/s31.dat\n",
      "D:/Major Project/data_preprocessed_python/s32.dat\n",
      "\n",
      "Print Successful\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "nLabel, nTrial, nUser, nChannel, nTime  = 4, 40, 32, 40, 8064\n",
    "no_of_users=32\n",
    "def convertData():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_data = open(\"D:/Major Project/data/features_raw.dat\",'w')\n",
    "    fout_labels0 = open(\"D:/Major Project/data/labels_0.dat\",'w')\n",
    "    fout_labels1 = open(\"D:/Major Project/data/labels_1.dat\",'w')\n",
    "    fout_labels2 = open(\"D:/Major Project/data/labels_2.dat\",'w')\n",
    "    fout_labels3 = open(\"D:/Major Project/data/labels_3.dat\",'w')\n",
    "    for i in range(no_of_users):  #nUser #4, 40, 32, 40, 8064 4 labels, 40 sample for each user, 32 such user, 40 electrode, 8064*40 features\n",
    "        if(i%1 == 0):\n",
    "            if i < 10:\n",
    "                name = '%0*d' % (2,i+1)\n",
    "            else:\n",
    "                name = i+1\n",
    "        fname = \"D:/Major Project/data_preprocessed_python/s\"+str(name)+\".dat\"     \n",
    "        f = open(fname, 'rb')                 #Read the file in Binary mode\n",
    "        x = pickle.load(f, encoding='latin1')\n",
    "        print(fname)                          \n",
    "    \t\n",
    "        for tr in range(nTrial):\n",
    "            if(tr%1 == 0):\n",
    "                for dat in range(nTime):\n",
    "                    if(dat%32 == 0):\n",
    "                        for ch in range(nChannel):\n",
    "                            fout_data.write(str(x['data'][tr][ch][dat]) + \" \");\n",
    "                fout_labels0.write(str(x['labels'][tr][0]) + \"\\n\");\n",
    "                fout_labels1.write(str(x['labels'][tr][1]) + \"\\n\");\n",
    "                fout_labels2.write(str(x['labels'][tr][2]) + \"\\n\");\n",
    "                fout_labels3.write(str(x['labels'][tr][3]) + \"\\n\");\n",
    "                fout_data.write(\"\\n\");\n",
    "    fout_labels0.close()\n",
    "    fout_labels1.close()\n",
    "    fout_labels2.close()\n",
    "    fout_labels3.close()\n",
    "    fout_data.close()\n",
    "    print(\"\\n\"+\"Print Successful\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convertData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5356a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "D:/Major Project/data_preprocessed_python/s01.dat\n",
      "D:/Major Project/data_preprocessed_python/s02.dat\n",
      "D:/Major Project/data_preprocessed_python/s03.dat\n",
      "D:/Major Project/data_preprocessed_python/s04.dat\n",
      "D:/Major Project/data_preprocessed_python/s05.dat\n",
      "D:/Major Project/data_preprocessed_python/s06.dat\n",
      "D:/Major Project/data_preprocessed_python/s07.dat\n",
      "D:/Major Project/data_preprocessed_python/s08.dat\n",
      "D:/Major Project/data_preprocessed_python/s09.dat\n",
      "D:/Major Project/data_preprocessed_python/s10.dat\n",
      "D:/Major Project/data_preprocessed_python/s11.dat\n",
      "D:/Major Project/data_preprocessed_python/s12.dat\n",
      "D:/Major Project/data_preprocessed_python/s13.dat\n",
      "D:/Major Project/data_preprocessed_python/s14.dat\n",
      "D:/Major Project/data_preprocessed_python/s15.dat\n",
      "D:/Major Project/data_preprocessed_python/s16.dat\n",
      "D:/Major Project/data_preprocessed_python/s17.dat\n",
      "D:/Major Project/data_preprocessed_python/s18.dat\n",
      "D:/Major Project/data_preprocessed_python/s19.dat\n",
      "D:/Major Project/data_preprocessed_python/s20.dat\n",
      "D:/Major Project/data_preprocessed_python/s21.dat\n",
      "D:/Major Project/data_preprocessed_python/s22.dat\n",
      "D:/Major Project/data_preprocessed_python/s23.dat\n",
      "D:/Major Project/data_preprocessed_python/s24.dat\n",
      "D:/Major Project/data_preprocessed_python/s25.dat\n",
      "D:/Major Project/data_preprocessed_python/s26.dat\n",
      "D:/Major Project/data_preprocessed_python/s27.dat\n",
      "D:/Major Project/data_preprocessed_python/s28.dat\n",
      "D:/Major Project/data_preprocessed_python/s29.dat\n",
      "D:/Major Project/data_preprocessed_python/s30.dat\n",
      "D:/Major Project/data_preprocessed_python/s31.dat\n",
      "D:/Major Project/data_preprocessed_python/s32.dat\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "nLabel, nTrial, nUser, nChannel, nTime  = 4, 40, 32, 40, 8064  #10080/80=126*40=5040 features\n",
    "no_of_users=32\n",
    "def sampleFeatures():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_data = open('D:/Major Project/data/features_sampled.dat','w')\n",
    "    for i in range(no_of_users):   #nUser  #4, 40, 32, 40, 8064\n",
    "        if(i%1 == 0):\n",
    "            if i < 10:\t\t\t\n",
    "                name = '%0*d' % (2,i+1)\n",
    "            else:\n",
    "                name = i+1\t\t\n",
    "            fname = \"D:/Major Project/data_preprocessed_python/s\"+str(name)+\".dat\"\n",
    "            x = pickle.load(open(fname, 'rb'), encoding='latin1')\t\t\n",
    "            print(fname)\t\t\n",
    "            for tr in range(nTrial):\t\t\t\n",
    "                if(tr%1 == 0):\t\t\t\t\n",
    "                    for dat in range(nTime):\t\t\t\t\t\n",
    "                        if(dat%32 == 0 ):\t\t\t\t\t\t\n",
    "                            for ch in range(nChannel):\t\t\t\t\t\t\t\n",
    "                                fout_data.write(str(ch+1) + \" \");\t\t\t\t\t\t\t\n",
    "                                fout_data.write(str(x['data'][tr][ch][dat]) + \" \");\t\t\t\n",
    "                fout_data.write(\"\\n\");\n",
    "    fout_data.close()\n",
    "    print('Completed')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sampleFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21571f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "Encoded label 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def onehotencoding0():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_labels_class = open(\"D:/Major Project/data/label_class_0.dat\",'w')\n",
    "    \n",
    "    with open('D:/Major Project/data/labels_0.dat','r') as f:\n",
    "        for val in f:\n",
    "            if float(val) > 4.5:\n",
    "                fout_labels_class.write(str(1) + \"\\n\");\n",
    "            else:\n",
    "                fout_labels_class.write(str(0) + \"\\n\");\n",
    "                \n",
    "    print(\"Encoded label 0\"+\"\\n\")\n",
    "if __name__ == '__main__':\n",
    "    onehotencoding0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371fa795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "Encoded label 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def onehotencoding1():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_labels_class = open(\"D:/Major Project/data/label_class_1.dat\",'w')\n",
    "    \n",
    "    with open('D:/Major Project/data/labels_1.dat','r') as f:\n",
    "        for val in f:\n",
    "            if float(val) > 4.5:\n",
    "                fout_labels_class.write(str(1) + \"\\n\");\n",
    "            else:\n",
    "                fout_labels_class.write(str(0) + \"\\n\");\n",
    "    print(\"Encoded label 1\"+\"\\n\")\n",
    "if __name__ == '__main__':\n",
    "    onehotencoding1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33647155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "Encoded label 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def onehotencoding1():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_labels_class = open(\"D:/Major Project/data/label_class_2.dat\",'w')\n",
    "    \n",
    "    with open('D:/Major Project/data/labels_2.dat','r') as f:\n",
    "        for val in f:\n",
    "            if float(val) > 4.5:\n",
    "                fout_labels_class.write(str(1) + \"\\n\");\n",
    "            else:\n",
    "                fout_labels_class.write(str(0) + \"\\n\");\n",
    "    print(\"Encoded label 2\"+\"\\n\")\n",
    "if __name__ == '__main__':\n",
    "    onehotencoding1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331a2504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program started\n",
      "\n",
      "Encoded label 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def onehotencoding3():\n",
    "    print(\"Program started\"+\"\\n\")\n",
    "    fout_labels_class = open(\"D:/Major Project/data/label_class_3.dat\",'w')\n",
    "    \n",
    "    with open('D:/Major Project/data/labels_3.dat','r') as f:\n",
    "        for val in f:\n",
    "            if float(val) > 4.5:\n",
    "                fout_labels_class.write(str(1) + \"\\n\");\n",
    "            else:\n",
    "                fout_labels_class.write(str(0) + \"\\n\");\n",
    "    print(\"Encoded label 3\"+\"\\n\")\n",
    "if __name__ == '__main__':\n",
    "    onehotencoding3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visual():\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from pandas.plotting import scatter_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import warnings\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    features = pd.read_csv('features.csv') \n",
    "    labels = pd.read_csv('labels.csv')\n",
    "\n",
    "    names = ['valence', 'arousal', 'dominance', 'liking']\n",
    "    dataset =features.transpose().reindex()\n",
    "\n",
    "\n",
    "# Summary of dataset\n",
    "    print('Summary of dataset\\n')\n",
    "# shape\n",
    "    print('1. Shape is:')\n",
    "    print(dataset.shape)\n",
    "# head\n",
    "    print('\\n2. First 8 rows are as:')\n",
    "    print(dataset.head(8))\n",
    "# descriptions\n",
    "    print('\\n3. Statistical description:')\n",
    "    print(dataset.describe())\n",
    "    types = dataset.dtypes\n",
    "    print('\\n4. Data Types:')\n",
    "    print(types)\n",
    "\n",
    "# Data visualisation\n",
    "# box and whisker plots\n",
    "    for i in range(5):\n",
    "        sns.set_style('whitegrid')\n",
    "        sns.boxplot(dataset[i])\n",
    "        plt.title('Magnitude versus ' + str(i+1) + ' channel')\n",
    "        plt.show()\n",
    "    \n",
    "    import seaborn as sns\n",
    "    from matplotlib import pyplot as plt\n",
    "    for i in range(5):\n",
    "        sns.distplot(dataset[i])\n",
    "        plt.title('Magnitude versus ' + str(i+1) + ' channel')\n",
    "        plt.show()\n",
    "if __name__ == '__main__':\n",
    "   data_visual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae36c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43  48]\n",
      " [ 63 102]]\n",
      "Accuracy score of Valence \n",
      "56.640625\n",
      "[[ 30  60]\n",
      " [ 52 114]]\n",
      "Accuracy score of Arousal \n",
      "56.25\n",
      "[[ 14  62]\n",
      " [ 21 159]]\n",
      "Accuracy score of Dominance \n",
      "67.578125\n",
      "[[  1  78]\n",
      " [ 11 166]]\n",
      "Accuracy score of Liking \n",
      "65.234375\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def knn_classifier():\n",
    "    file_x = 'D:/Major Project/data/features_sampled.dat'\n",
    "    file_y = 'D:/Major Project/data/label_class_0.dat'\n",
    "    \n",
    "    X = numpy.genfromtxt(file_x, delimiter=' ')\n",
    "    y = numpy.genfromtxt(file_y, delimiter=' ')\n",
    "    \n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \t\n",
    "    # KNN\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score of Valence \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    file_x = 'D:/Major Project/data/features_sampled.dat'\n",
    "    file_y = 'D:/Major Project/data/label_class_1.dat'\n",
    "    \n",
    "    X = numpy.genfromtxt(file_x, delimiter=' ')\n",
    "    y = numpy.genfromtxt(file_y, delimiter=' ')\n",
    "    \n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \t\n",
    "    # KNN\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score of Arousal \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    file_x = 'D:/Major Project/data/features_sampled.dat'\n",
    "    file_y = 'D:/Major Project/data/label_class_2.dat'\n",
    "    \n",
    "    X = numpy.genfromtxt(file_x, delimiter=' ')\n",
    "    y = numpy.genfromtxt(file_y, delimiter=' ')\n",
    "    \n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \t\n",
    "    # KNN\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score of Dominance \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    file_x = 'D:/Major Project/data/features_sampled.dat'\n",
    "    file_y = 'D:/Major Project/data/label_class_3.dat'\n",
    "    \n",
    "    X = numpy.genfromtxt(file_x, delimiter=' ')\n",
    "    y = numpy.genfromtxt(file_y, delimiter=' ')\n",
    "    \n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \t\n",
    "    # KNN\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score of Liking \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    knn_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
